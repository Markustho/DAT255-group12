{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/markusayt/src-models-notebookea554506b2?scriptVersionId=162606177\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-12T11:16:09.524762Z","iopub.status.busy":"2024-02-12T11:16:09.524379Z","iopub.status.idle":"2024-02-12T11:16:09.532321Z","shell.execute_reply":"2024-02-12T11:16:09.530879Z","shell.execute_reply.started":"2024-02-12T11:16:09.524735Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","import torch\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-12T11:16:09.53476Z","iopub.status.busy":"2024-02-12T11:16:09.534367Z","iopub.status.idle":"2024-02-12T11:16:09.545226Z","shell.execute_reply":"2024-02-12T11:16:09.543916Z","shell.execute_reply.started":"2024-02-12T11:16:09.53473Z"},"trusted":true},"outputs":[],"source":["#Check for colab or kaggle\n","try:\n","    import google.colab\n","    colab=True\n","except:\n","    colab=False\n","\n","import os\n","kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-12T11:16:09.547403Z","iopub.status.busy":"2024-02-12T11:16:09.547041Z","iopub.status.idle":"2024-02-12T11:16:09.568911Z","shell.execute_reply":"2024-02-12T11:16:09.567986Z","shell.execute_reply.started":"2024-02-12T11:16:09.547375Z"},"trusted":true},"outputs":[],"source":["#check for internet on in kaggle if the client is run on kaggle\n","import socket,warnings\n","if kaggle:\n","\n","    try:\n","        socket.setdefaulttimeout(1)\n","        socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))\n","    except socket.error as ex: raise Exception(\"STOP: No internet. Click '>|' in top right and set 'Internet' switch to on\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-12T11:16:09.571965Z","iopub.status.busy":"2024-02-12T11:16:09.570983Z","iopub.status.idle":"2024-02-12T11:16:09.577381Z","shell.execute_reply":"2024-02-12T11:16:09.57656Z","shell.execute_reply.started":"2024-02-12T11:16:09.571933Z"},"trusted":true},"outputs":[],"source":["#If using FastAI, this will need to be ran to give latest version\n","\"\"\"if colab:\n","    !pip install -Uqq fastbook\n","    import fastbook\n","    fastbook.setup_book()\n","\n","elif kaggle:\n","    !pip install -Uqq fastai\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-12T11:16:09.579361Z","iopub.status.busy":"2024-02-12T11:16:09.578786Z","iopub.status.idle":"2024-02-12T11:16:09.590175Z","shell.execute_reply":"2024-02-12T11:16:09.588879Z","shell.execute_reply.started":"2024-02-12T11:16:09.579321Z"},"trusted":true},"outputs":[],"source":["# Opening from different sources to allow for use of local IDE as well as run in kaggle\n","# Kaggle and local version is linked through github\n","\n","from pathlib import Path\n","if colab:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\")\n","    DATA = Path('/content/gdrive/MyDrive/DAT255/')\n","    DATA.mkdir(exist_ok=True, parents=True)\n","    \n","elif kaggle:\n","    DATA = Path('/kaggle/input/turbine-data/Onsite-MetMast-SCADA-data-2017.xlsx')\n","    DATAScada = Path(\"/kaggle/input/turbine-data/Wind-Turbine-SCADA-signals-2017_0.xlsx\")\n","    DATAFailures = Path(\"/kaggle/input/turbine-data/opendata-wind-failures-2017.xlsx\")\n","\n","else:\n","    DATA = \"../../data/processed/Onsite-MetMast-SCADA-data-2017.xlsx\"\n","    DATAScada = \"../../data/processed/Wind-Turbine-SCADA-signals-2017_0.xlsx\"\n","    DATAFailures = \"../../data/processed/opendata-wind-failures-2017.xlsx\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-12T11:16:09.593213Z","iopub.status.busy":"2024-02-12T11:16:09.592485Z","iopub.status.idle":"2024-02-12T11:16:31.602601Z","shell.execute_reply":"2024-02-12T11:16:31.601185Z","shell.execute_reply.started":"2024-02-12T11:16:09.593177Z"},"trusted":true},"outputs":[],"source":["# opening excel file for processed data from 2017\n","data = pd.read_excel(DATA, engine='openpyxl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# opening excel file for Scada data from 2017\n","datascada = pd.read_excel(DATAScada, engine='openpyxl')"]},{"cell_type":"markdown","metadata":{},"source":["### Testing colum sorting with dataframes in pandas\n","testing how to open and organize data using columns on failure dataset. This dataset is smaller, but is still based on time, so its good to do some tests on this one before the big datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# opening excel file for failures of all turbines in 2017\n","datafailures = pd.read_excel(DATAFailures, engine=\"openpyxl\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sort by turbine T07\n","T07Failures = datafailures[datafailures[\"Turbine_ID\"] == \"T07\"]\n","T07Failures # printing to show example of how how it looks. datafailures is only a small file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["T07_scada_data = datascada[datascada[\"Turbine_ID\"] == \"T07\"] # sorting data from T07 turbine"]},{"cell_type":"markdown","metadata":{},"source":["We will now proceed with an inner join to get rid of NaN and missing data. Ideally we should try and do a mode replacement of the data at some point also. See Lesson 5 practical programming video with FastAI"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#combining the data with respect to datetime. This is the inner join of enviromental data and turbine data for a respective timestamp\n","merged_df = pd.merge(T07_scada_data, data, on=\"Timestamp\", how=\"inner\")\n","\n","merged_df_outer_join = pd.merge(T07_scada_data,data, on=\"Timestamp\", how=\"outer\") #this one will have NaN and other imperfections. Modify at later stage"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df_outer_join.isna().sum().to_excel(\"outer_join.xlsx\") #Just checking the scope of missing values. This command sums the amount of missing values for each column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check title fields\n","for i in merged_df:\n","    print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plotting some data to look for outliers and anomalties in the data itself. Visualize the data\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","\n","#for i in merged_df:\n","merged_df['Timestamp'] = pd.to_datetime(merged_df['Timestamp'])\n","\n","ax = merged_df.plot.scatter(x=\"Timestamp\", y=\"Gen_Bear_Temp_Avg\")\n","\n","# Customize the format of the timestamp on the x-axis\n","ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n","\n","# Optionally, set the locator for more control over tick placement\n","ax.xaxis.set_major_locator(mdates.DayLocator())  # You can adjust the locator based on your data frequency\n","\n","# Rotate x-axis labels for better readability\n","plt.xticks(rotation=45, ha='right')\n","#Define interval for data\n","plt.xlim(pd.Timestamp('2017-11-15'), pd.Timestamp('2017-12-01'))\n","\n","# Add labels and title\n","plt.xlabel('Timestamp')\n","plt.ylabel('Gen_Bear_Temp_Avg')\n","plt.title('Scatter Plot of Gen_Bear_Temp_Avg over Time')\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check the \"spread\" of the data in a column\n","#this is interesting because often we do now want a long tail distribution of our data!\n","# for longtail distributions. make distribution logaritmic\n","merged_df[\"Gear_Oil_Temp_Avg\"].hist()"]},{"cell_type":"markdown","metadata":{},"source":["### Creating the model:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","#merged_df.isnull().sum().to_excel('na_summary.xlsx')\n","merged_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#import torch\n","#remove turbine id to have only numbers in dataframe\n","merged_df = merged_df.dropna()\n","merged_df = merged_df.drop(\"Turbine_ID\", axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#dropping columns with NaN and Inf values showing up later\n","\n","merged_df = merged_df.drop(merged_df.columns[70], axis=1)\n","merged_df = merged_df.drop(merged_df.columns[70], axis=1)\n","merged_df = merged_df.drop(merged_df.columns[70], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","#remove columns where all numbers are 0\n","cols_to_remove = merged_df.columns[(merged_df == 0).all()]\n","\n","# Drop those columns from the DataFrame\n","merged_df_filtered = merged_df.drop(cols_to_remove, axis=1)\n","\n","#create a list of independent variable names [\"name1\", \"name2\"] etc etc\n","indep_cols = merged_df_filtered.columns.to_list()\n","indep_cols\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#datetime needs to be a able to convert to a float. Making it just a month as a number between 1 and 12\n","if isinstance(merged_df_filtered[\"Timestamp\"].iloc[2], pd.Timestamp):\n","    merged_df_filtered['Timestamp'] = merged_df_filtered['Timestamp'].dt.month.astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df_filtered.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#creates a tensor t_indep from merged_df.values for the independent variables and saves them as flaots in torch format\n","t_indep = tensor(merged_df_filtered[indep_cols].values, dtype=torch.float)\n","t_indep"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dependent variable\n","# our dependent is going to be generator bearing average temperature \"Gen_Bear_Temp_Avg\"\n","\n","t_dep = tensor(merged_df_filtered.Gen_Bear_Temp_Avg.values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_coeff = t_indep.shape[1] #number of coefficients in our model\n","coeffs = torch.rand(n_coeff)-0.5\n","coeffs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#checking if compatible with lesson. Jeremy explains broadcasting. \n","#t_indep*coeffs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#To improve our model we do the element wise division of the maximum of each column.\n","# This is to improve the properties of the model when multiplications are being performed by numbers less than 1\n","# we want all values in the dataset to be \"simular size\" and is called normalizing\n","\n","\n","vals, indices = t_indep.max(dim=0)\n","\n","\n","\n","## print as excel to inspect the data\n","\n","vals[:]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_indep = t_indep / vals"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#making a prediction with our random coefficients:\n","preds = (t_indep*coeffs).sum(axis=1)\n","preds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds[:1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss = torch.abs(preds-t_dep).mean()\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_indep[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4421458,"sourceId":7596068,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
